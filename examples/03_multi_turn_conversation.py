#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯ - ç†è§£è®°å¿†ç³»ç»Ÿ

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ï¼š
1. è¿›è¡Œå¤šè½®å¯¹è¯
2. ç†è§£ Memory å¦‚ä½•ç»´æŠ¤ä¸Šä¸‹æ–‡
3. æŸ¥çœ‹å’Œç®¡ç†å¯¹è¯å†å²

è®°å¿†çš„ä½œç”¨ï¼š
- å­˜å‚¨å¯¹è¯å†å²
- ä¸º LLM æä¾›ä¸Šä¸‹æ–‡
- è®©æ™ºèƒ½ä½“"è®°ä½"ä¹‹å‰è¯´è¿‡çš„è¯

è¿è¡Œæ–¹å¼:
    # ä½¿ç”¨ DashScopeï¼ˆæ¨èï¼‰
    export DASHSCOPE_API_KEY="sk-xxx"
    python 03_multi_turn_conversation.py
    
    # æˆ–ä½¿ç”¨ OpenAI
    export OPENAI_API_KEY="sk-xxx"
    python 03_multi_turn_conversation.py --openai
"""

import asyncio
import os
import sys

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

from nano_agentscope import (
    ReActAgent,
    UserAgent,
    DashScopeChatModel,
    OpenAIChatModel,
    OpenAIFormatter,
    InMemoryMemory,
    Msg,
)


def create_model(use_openai: bool = False):
    """åˆ›å»º LLM æ¨¡å‹"""
    if use_openai:
        return OpenAIChatModel(model_name="gpt-4o-mini", stream=True)
    else:
        return DashScopeChatModel(model_name="qwen-max", stream=True)


async def main(use_openai: bool = False):
    """äº¤äº’å¼å¤šè½®å¯¹è¯"""
    
    model = create_model(use_openai)
    print(f"ä½¿ç”¨æ¨¡å‹: {model.model_name}")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = ReActAgent(
        name="è®°å¿†åŠ©æ‰‹",
        sys_prompt="""ä½ æ˜¯ä¸€ä¸ªå…·æœ‰è‰¯å¥½è®°å¿†åŠ›çš„ AI åŠ©æ‰‹ã€‚
è¯·è®°ä½ç”¨æˆ·å‘Šè¯‰ä½ çš„ä¿¡æ¯ï¼Œå¹¶åœ¨åç»­å¯¹è¯ä¸­ä½¿ç”¨è¿™äº›ä¿¡æ¯ã€‚
å›ç­”è¦ç®€æ´å‹å¥½ã€‚""",
        model=model,
        formatter=OpenAIFormatter(),
        memory=InMemoryMemory(),
    )
    
    # åˆ›å»ºç”¨æˆ·æ™ºèƒ½ä½“
    user = UserAgent("ç”¨æˆ·")
    
    print("=" * 50)
    print("å¤šè½®å¯¹è¯ç¤ºä¾‹ - è¾“å…¥ 'exit' é€€å‡º")
    print("è¾“å…¥ 'memory' æŸ¥çœ‹å½“å‰è®°å¿†")
    print("è¾“å…¥ 'clear' æ¸…ç©ºè®°å¿†")
    print("=" * 50)
    
    msg = None
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        msg = await user(msg)
        
        user_text = msg.get_text_content()
        
        # ç‰¹æ®Šå‘½ä»¤å¤„ç†
        if user_text.lower() == "exit":
            print("å†è§ï¼")
            break
        
        if user_text.lower() == "memory":
            # æ˜¾ç¤ºå½“å‰è®°å¿†
            print("\n" + "=" * 30 + " å½“å‰è®°å¿† " + "=" * 30)
            memories = await agent.memory.get_memory()
            for i, mem in enumerate(memories):
                text = mem.get_text_content() or str(mem.content)[:100]
                print(f"[{i}] {mem.role}/{mem.name}: {text[:50]}...")
            print("=" * 70 + "\n")
            msg = None
            continue
        
        if user_text.lower() == "clear":
            await agent.memory.clear()
            print("è®°å¿†å·²æ¸…ç©ºï¼\n")
            msg = None
            continue
        
        # æ­£å¸¸å¯¹è¯
        msg = await agent(msg)


async def demo_memory_context(use_openai: bool = False):
    """æ¼”ç¤ºè®°å¿†å¦‚ä½•æä¾›ä¸Šä¸‹æ–‡"""
    
    print("\n" + "=" * 50)
    print("æ¼”ç¤ºï¼šè®°å¿†å¦‚ä½•å¸®åŠ©æ™ºèƒ½ä½“ç†è§£ä¸Šä¸‹æ–‡")
    print("=" * 50)
    
    model = create_model(use_openai)
    model.stream = False  # æ¼”ç¤ºç”¨éæµå¼
    print(f"ä½¿ç”¨æ¨¡å‹: {model.model_name}")
    
    agent = ReActAgent(
        name="åŠ©æ‰‹",
        sys_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œè¯·è®°ä½ç”¨æˆ·çš„ä¿¡æ¯ã€‚",
        model=model,
        formatter=OpenAIFormatter(),
    )
    
    # ç¬¬ä¸€è½®ï¼šä»‹ç»ä¿¡æ¯
    print("\n--- ç¬¬ä¸€è½®å¯¹è¯ ---")
    await agent(Msg(name="user", content="æˆ‘å«å¼ ä¸‰ï¼Œä»Šå¹´25å²ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜ã€‚", role="user"))
    
    # ç¬¬äºŒè½®ï¼šåŸºäºä¸Šä¸‹æ–‡çš„é—®é¢˜
    print("\n--- ç¬¬äºŒè½®å¯¹è¯ ---")
    await agent(Msg(name="user", content="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿåšä»€ä¹ˆå·¥ä½œï¼Ÿ", role="user"))
    
    # æ˜¾ç¤ºè®°å¿†çŠ¶æ€
    print("\n--- è®°å¿†çŠ¶æ€ ---")
    memories = await agent.memory.get_memory()
    print(f"å…±æœ‰ {len(memories)} æ¡è®°å¿†")
    for mem in memories:
        role = "ğŸ‘¤" if mem.role == "user" else "ğŸ¤–"
        text = mem.get_text_content() or "[éæ–‡æœ¬å†…å®¹]"
        print(f"  {role} {mem.name}: {text[:60]}...")


if __name__ == "__main__":
    use_openai = "--openai" in sys.argv
    
    if use_openai:
        if not os.environ.get("OPENAI_API_KEY"):
            print("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            sys.exit(1)
    else:
        if not os.environ.get("DASHSCOPE_API_KEY"):
            print("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
            print("export DASHSCOPE_API_KEY='sk-xxx'")
            print("\næˆ–ä½¿ç”¨: python 03_multi_turn_conversation.py --openai")
            sys.exit(1)
    
    # å…ˆè¿è¡Œæ¼”ç¤º
    asyncio.run(demo_memory_context(use_openai))
    
    print("\n" + "=" * 50)
    print("ç°åœ¨è¿›å…¥äº¤äº’æ¨¡å¼...")
    print("=" * 50)
    
    # è¿›å…¥äº¤äº’æ¨¡å¼
    asyncio.run(main(use_openai))
